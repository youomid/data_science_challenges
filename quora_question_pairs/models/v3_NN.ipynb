{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "import swifter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decisions\n",
    "1. Use keras hyperparameter tuner to optimize learning rate, # of neurons, epochs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8833777564792535668\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5897977856\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 649234863903934078\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_lemma</th>\n",
       "      <th>question2_lemma</th>\n",
       "      <th>simple_ratio</th>\n",
       "      <th>partial_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>question1_length</th>\n",
       "      <th>question2_length</th>\n",
       "      <th>question1_punctuation_count</th>\n",
       "      <th>question2_punctuation_count</th>\n",
       "      <th>question1_hash</th>\n",
       "      <th>question2_hash</th>\n",
       "      <th>question1_degree</th>\n",
       "      <th>question2_degree</th>\n",
       "      <th>question1_degree_deviation</th>\n",
       "      <th>question2_degree_deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>224553</td>\n",
       "      <td>371</td>\n",
       "      <td>27778</td>\n",
       "      <td>What was the significance of the battle of Som...</td>\n",
       "      <td>What was the significance of the battle of Som...</td>\n",
       "      <td>1</td>\n",
       "      <td>wa significance battle somme  battle compare c...</td>\n",
       "      <td>wa significance battle somme  battle compare c...</td>\n",
       "      <td>64</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>What was the significance of the battle of Som...</td>\n",
       "      <td>What was the significance of the battle of Som...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>18.495282</td>\n",
       "      <td>18.495282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31197</td>\n",
       "      <td>57541</td>\n",
       "      <td>8255</td>\n",
       "      <td>How do I get meth out of my system in 2 days?</td>\n",
       "      <td>How can I get meth out of my system ASAP?</td>\n",
       "      <td>1</td>\n",
       "      <td>get meth system 2 days</td>\n",
       "      <td>get meth system asap</td>\n",
       "      <td>50</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>How do I get meth out of my system in 2 days?</td>\n",
       "      <td>How can I get meth out of my system ASAP?</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>15.495282</td>\n",
       "      <td>15.495282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310228</td>\n",
       "      <td>23108</td>\n",
       "      <td>29504</td>\n",
       "      <td>Why is salt water taffy candy imported in France?</td>\n",
       "      <td>Why is saltwater taffy candy imported in Brazil?</td>\n",
       "      <td>1</td>\n",
       "      <td>salt water taffy candy import france</td>\n",
       "      <td>saltwater taffy candy import brazil</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Why is salt water taffy candy imported in France?</td>\n",
       "      <td>Why is saltwater taffy candy imported in Brazil?</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>24.495282</td>\n",
       "      <td>25.495282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15827</td>\n",
       "      <td>30203</td>\n",
       "      <td>30204</td>\n",
       "      <td>What is the best way to take a picture with a ...</td>\n",
       "      <td>How do I take good pictures with my phone?</td>\n",
       "      <td>1</td>\n",
       "      <td>best way take picture phone</td>\n",
       "      <td>take good picture phone</td>\n",
       "      <td>57</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the best way to take a picture with a ...</td>\n",
       "      <td>How do I take good pictures with my phone?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.504718</td>\n",
       "      <td>-0.504718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128555</td>\n",
       "      <td>206708</td>\n",
       "      <td>206709</td>\n",
       "      <td>Who is the most beautiful actress in China?</td>\n",
       "      <td>Who is the most beautiful actress in Europe?</td>\n",
       "      <td>0</td>\n",
       "      <td>beautiful actress china</td>\n",
       "      <td>beautiful actress europe</td>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Who is the most beautiful actress in China?</td>\n",
       "      <td>Who is the most beautiful actress in Europe?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495282</td>\n",
       "      <td>0.495282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0  224553     371   27778  What was the significance of the battle of Som...   \n",
       "1   31197   57541    8255      How do I get meth out of my system in 2 days?   \n",
       "2  310228   23108   29504  Why is salt water taffy candy imported in France?   \n",
       "3   15827   30203   30204  What is the best way to take a picture with a ...   \n",
       "4  128555  206708  206709        Who is the most beautiful actress in China?   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What was the significance of the battle of Som...             1   \n",
       "1          How can I get meth out of my system ASAP?             1   \n",
       "2   Why is saltwater taffy candy imported in Brazil?             1   \n",
       "3         How do I take good pictures with my phone?             1   \n",
       "4       Who is the most beautiful actress in Europe?             0   \n",
       "\n",
       "                                     question1_lemma  \\\n",
       "0  wa significance battle somme  battle compare c...   \n",
       "1                            get meth system 2 days    \n",
       "2              salt water taffy candy import france    \n",
       "3                       best way take picture phone    \n",
       "4                           beautiful actress china    \n",
       "\n",
       "                                     question2_lemma  simple_ratio  \\\n",
       "0  wa significance battle somme  battle compare c...            64   \n",
       "1                              get meth system asap             50   \n",
       "2               saltwater taffy candy import brazil             73   \n",
       "3                           take good picture phone             57   \n",
       "4                          beautiful actress europe             62   \n",
       "\n",
       "   partial_ratio  ...  question1_length  question2_length  \\\n",
       "0             91  ...               119               123   \n",
       "1             81  ...                45                41   \n",
       "2             86  ...                49                48   \n",
       "3             79  ...                52                42   \n",
       "4             75  ...                43                44   \n",
       "\n",
       "   question1_punctuation_count  question2_punctuation_count  \\\n",
       "0                            2                            2   \n",
       "1                            1                            1   \n",
       "2                            1                            1   \n",
       "3                            1                            1   \n",
       "4                            1                            1   \n",
       "\n",
       "                                      question1_hash  \\\n",
       "0  What was the significance of the battle of Som...   \n",
       "1      How do I get meth out of my system in 2 days?   \n",
       "2  Why is salt water taffy candy imported in France?   \n",
       "3  What is the best way to take a picture with a ...   \n",
       "4        Who is the most beautiful actress in China?   \n",
       "\n",
       "                                      question2_hash  question1_degree  \\\n",
       "0  What was the significance of the battle of Som...                20   \n",
       "1          How can I get meth out of my system ASAP?                17   \n",
       "2   Why is saltwater taffy candy imported in Brazil?                26   \n",
       "3         How do I take good pictures with my phone?                 1   \n",
       "4       Who is the most beautiful actress in Europe?                 2   \n",
       "\n",
       "   question2_degree question1_degree_deviation question2_degree_deviation  \n",
       "0                20                  18.495282                  18.495282  \n",
       "1                17                  15.495282                  15.495282  \n",
       "2                27                  24.495282                  25.495282  \n",
       "3                 1                  -0.504718                  -0.504718  \n",
       "4                 2                   0.495282                   0.495282  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_NAME = 'dataset_v2'\n",
    "train_df = pd.read_csv(f'../output/train_{DATASET_NAME}.csv')\n",
    "valid_df = pd.read_csv(f'../output/valid_{DATASET_NAME}.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['simple_ratio', 'partial_ratio', 'token_sort_ratio', 'token_set_ratio', 'question1_type', 'question2_type', 'question1_punctuation_count', 'question2_punctuation_count']\n",
    "\n",
    "train_is_duplicate_df = train_df[['is_duplicate']].copy()\n",
    "train_features_df = train_df[features].copy()\n",
    "\n",
    "valid_is_duplicate_df = valid_df[['is_duplicate']].copy()\n",
    "valid_features_df = valid_df[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 03m 10s]\n",
      "val_loss: 0.5368462800979614\n",
      "\n",
      "Best val_loss So Far: 0.5356546640396118\n",
      "Total elapsed time: 00h 36m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/15\n",
      "259/259 [==============================] - 1s 3ms/step - loss: 0.6163 - val_loss: 0.6648\n",
      "Epoch 2/15\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5801 - val_loss: 0.6373\n",
      "Epoch 3/15\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5676 - val_loss: 0.6044\n",
      "Epoch 4/15\n",
      "259/259 [==============================] - 1s 3ms/step - loss: 0.5602 - val_loss: 0.5901\n",
      "Epoch 5/15\n",
      "259/259 [==============================] - 1s 3ms/step - loss: 0.5545 - val_loss: 0.5709\n",
      "Epoch 6/15\n",
      "259/259 [==============================] - 1s 3ms/step - loss: 0.5484 - val_loss: 0.5474\n",
      "Epoch 7/15\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5418 - val_loss: 0.5521\n",
      "Epoch 8/15\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5373 - val_loss: 0.5396\n",
      "Epoch 9/15\n",
      "259/259 [==============================] - 1s 3ms/step - loss: 0.5362 - val_loss: 0.5400\n",
      "Epoch 10/15\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5357 - val_loss: 0.5412\n",
      "Epoch 11/15\n",
      "259/259 [==============================] - 1s 3ms/step - loss: 0.5354 - val_loss: 0.5389\n",
      "Epoch 12/15\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5354 - val_loss: 0.5384\n",
      "Epoch 13/15\n",
      "259/259 [==============================] - 1s 3ms/step - loss: 0.5352 - val_loss: 0.5374\n",
      "Epoch 14/15\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5347 - val_loss: 0.5374\n",
      "Epoch 15/15\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5346 - val_loss: 0.5389\n",
      "Best epoch: 1\n",
      "8086/8086 [==============================] - 19s 2ms/step - loss: 0.5867 - val_loss: 0.5602\n",
      "2527/2527 [==============================] - 3s 1ms/step - loss: 0.5612\n",
      "test loss: 0.5612156391143799\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(train_features_df.columns)\n",
    "\n",
    "def model_builder(hp):\n",
    "  model = Sequential()\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  input_layer_units = hp.Int('input_layer_units', min_value=4, max_value=16, step=2)\n",
    "  layer_1_units = hp.Int('layer_1_units', min_value=4, max_value=16, step=2)\n",
    "    \n",
    "  input_layer_activation = hp.Choice('input_layer_activation', values=['relu', 'tanh', 'sigmoid'], default='relu')\n",
    "  layer_activation_1 = hp.Choice('layer_activation_1', values=['relu', 'tanh', 'sigmoid'], default='relu')\n",
    "  \n",
    "  model.add(Dense(units=input_layer_units, input_dim=input_dim, activation=input_layer_activation))\n",
    "  model.add(Dense(units=layer_1_units, activation=layer_activation_1))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                loss='binary_crossentropy'\n",
    "                )\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective=kt.Objective('val_loss', direction='min'), # same as binary cross entropy\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='output',\n",
    "                     project_name='quora_question_pairs')\n",
    "\n",
    "stop_early = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "tuner.search(train_features_df, train_is_duplicate_df, epochs=15, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_features_df, train_is_duplicate_df, epochs=15, validation_split=0.2, batch_size=1000)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_loss']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n",
    "\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(train_features_df, train_is_duplicate_df, epochs=best_epoch, validation_split=0.2)\n",
    "\n",
    "eval_result = hypermodel.evaluate(valid_features_df, valid_is_duplicate_df)\n",
    "print(\"test loss:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 80858/80858 [00:00<00:00, 106301.33it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = hypermodel.predict(valid_features_df)\n",
    "\n",
    "def is_correct(row):\n",
    "    is_duplicate = True if row['is_duplicate'] == 1 else False\n",
    "    return is_duplicate == (predictions[row.name] > 0.5)\n",
    "\n",
    "valid_df['is_correct'] = valid_df.swifter.apply(lambda row: is_correct(row)[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = valid_df.loc[valid_df['is_correct'] == False]\n",
    "incorrect.to_csv(f'../output/v3_nn_{DATASET_NAME}_incorrect.csv', index=False)\n",
    "\n",
    "correct = valid_df.loc[valid_df['is_correct'] == True]\n",
    "correct.to_csv(f'../output/v3_nn_{DATASET_NAME}_correct.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3872f8dba59e6fb582868000b73f7396e403e1070facd46dc063100be0232eec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('data_science_challenges': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
